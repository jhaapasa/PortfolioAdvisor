# Architecture Overview

This document explains the overall design of PortfolioAdvisor: the data flow through its agents, state management approach, and guidance for extending the system.

For CLI usage and configuration options, see [README.md](../README.md).

## Design Goals
- **Simplicity:** Reliable end-to-end portfolio ingestion and analysis with minimal setup
- **Modularity:** Clear boundaries between ingestion, parsing, resolution, and analysis stages
- **Extensibility:** Easy to add new data providers, analysis types, and agents
- **Observability:** Transparent state management and comprehensive logging
- **Testability:** Deterministic agent behavior with >80% code coverage

## High-Level Flow

The system supports multiple analysis modes orchestrated through LangGraph pipelines:

### Portfolio Analysis Pipeline

The main portfolio flow follows a linear pipeline with parallel fan-out/fan-in stages:

1. **CLI Initialization**
   - Parses arguments and environment variables
   - Builds application settings
   - Configures logging and LLM caching
   - Invokes the appropriate analysis entrypoint

2. **Agent Orchestration** (LangGraph state machine)
   ```
   ingestion → planner → dispatch_parse → [parse_one × N] → join_after_parse →
   dispatch_resolve → [resolve_one × M] → join_after_resolve → analyst → END
   ```

3. **Output Generation**
   - Compiled analysis report (`analysis.md`)
   - Structured holdings data (`resolved_positions.json`)
   - Portfolio persistence (`output/portfolio/`)

### Stock Analysis Pipeline

Per-stock data collection and analysis:
```
fetch_ohlc → compute_returns → compute_volatility → compute_sma →
[optional: compute_wavelet] → [optional: fetch_news] → generate_charts → END
```

### Basket Analysis Pipeline

Group analysis for stock baskets:
```
load_basket → update_stock_data → compute_metrics → generate_narrative → END
```

### Agent Pipeline Stages

- **Ingestion:** Discovers and extracts plain text from input files
- **Planner:** Analyzes document structure and creates parsing strategy
- **Parse (fan-out):** LLM-powered extraction of holdings from each document in parallel
- **Resolve (fan-out):** Symbol resolution via Polygon.io for each holding in parallel
- **Analyst:** Generates narrative summary of portfolio composition and insights
- **Stock Update:** Fetches OHLC data, computes technical indicators, generates charts
- **Basket Narrative:** Generates LLM-powered analysis reports for stock groups

## LangGraph State Contract

The graph state is a typed dictionary with well-defined channels for data flow between agents:

### Core State Fields
- **`settings`** — Application configuration (immutable)
- **`raw_docs`** — List of ingested documents with metadata (path, MIME type, extracted text)
- **`plan`** — Parsing strategy with rationale from the planner agent

### Additive Channels
These channels accumulate results across parallel fan-out operations:
- **`parsed_holdings`** — Candidate holdings extracted from documents (pre-resolution)
- **`resolved_holdings`** — Canonical holdings with validated symbols and instrument keys
- **`unresolved_entities`** — Holdings that failed symbol resolution with error reasons
- **`errors`** — Error messages from any agent

### Output Channels
- **`analysis`** — Final narrative report generated by the analyst agent

### State Update Semantics
- Additive channels use the `operator.add` reducer to merge results from parallel nodes
- Single-value fields use last-write-wins semantics
- All state updates are immutable; agents return new state dictionaries

## Agent Implementations

### Portfolio Agents

#### Ingestion Agent (`agents/ingestion.py`)
**Purpose:** Extract structured text from heterogeneous input files

**Capabilities:**
- Discovers all files in `input_dir` recursively
- Supports multiple formats: TXT, MD, HTML, CSV, EML
- Applies 2 MiB hard cap per file for memory safety
- Filters OS artifacts (`.DS_Store`, hidden files)
- Extracts MIME type metadata for downstream processing

**Output:** Populates `raw_docs` state channel

#### Planner Agent (`agents/planner.py`)
**Purpose:** Analyze document structure and create parsing strategy

**Capabilities:**
- Inspects document types and content structure
- Generates step-by-step parsing plan with rationale
- Identifies document-specific extraction strategies

**Output:** Populates `plan` state field

#### Parser Agent (`agents/parser.py`)
**Purpose:** Extract holdings from documents using LLM-powered structured output

**Capabilities:**
- Fan-out: One parser instance per document (parallel execution)
- Prompts LLM to emit strict JSON matching `ParsedHoldingsResult` schema
- Automatic retry on validation errors (configurable via `PARSER_MAX_RETRIES`)
- Input truncation to `PARSER_MAX_DOC_CHARS` to manage token limits
- Schema-validated output with Pydantic models

**Output:** Accumulates results in `parsed_holdings` channel

#### Resolver Agent (`agents/resolver.py` + `tools/symbol_resolver.py`)
**Purpose:** Resolve ticker symbols to canonical instrument identifiers

**Capabilities:**
- Fan-out: One resolver call per holding (parallel execution)
- Queries Polygon.io Ticker Search API for symbol validation
- Heuristic ranking: active status + preferred MIC + currency match
- Confidence threshold filtering (configurable)
- Offline mode: gracefully handles missing API key
- Generates canonical `InstrumentKey` format: `cid:asset_class:locale:mic:symbol`

**Output:** Populates `resolved_holdings` and `unresolved_entities` channels

#### Analyst Agent (`agents/analyst.py`)
**Purpose:** Generate portfolio analysis report

**Capabilities:**
- Synthesizes insights from resolved holdings
- LLM-powered narrative generation
- Summarizes portfolio composition and allocation
- Identifies notable positions and concentrations

**Output:** Populates `analysis` state field

### Stock and Basket Agents

#### News Summary Agent (`agents/news_summary.py`)
**Purpose:** Aggregate and summarize news articles for stocks

**Capabilities:**
- Fetches recent news from Polygon.io
- Downloads and caches article HTML
- Generates LLM-powered news summaries
- Integrates with 7-day stock reports

#### Basket Narrative Agent (`agents/basket_narrative.py`)
**Purpose:** Generate narrative reports for stock baskets

**Capabilities:**
- Aggregates per-stock metrics across basket
- Computes basket-level performance statistics
- Generates LLM-powered comparative analysis
- Produces Markdown reports with metrics JSON

#### Stock Report Collator (`agents/stock_report_collator.py`)
**Purpose:** Collate 7-day stock news and technical reports

**Capabilities:**
- Combines news summaries with technical indicators
- Structures multi-section Markdown reports
- Embeds chart references for visual reports

#### Market Comparison Agent (`agents/market_comparison.py`)
**Purpose:** Compute market benchmark comparisons (planned feature)

**Capabilities:**
- Computes beta coefficients vs. market indices
- Calculates Sharpe ratios across time horizons
- Generates risk-adjusted performance comparisons

## Data Models

### Parsed Models (`models/parsed.py`)
Represents raw LLM extraction output before symbol resolution:

- **`ParsedHolding`** — Single holding with fields:
  - `ticker` — Raw ticker symbol from document
  - `quantity` — Number of shares/units
  - `description` — Asset description (optional)
  - `account` — Account identifier (optional)

- **`ParsedHoldingsResult`** — Container for parser output:
  - `holdings` — List of `ParsedHolding` objects
  - `metadata` — Extraction metadata (document name, parser version)

### Canonical Models (`models/canonical.py`)
Represents validated, normalized holdings after resolution:

- **`InstrumentKey`** — Globally unique identifier with format:
  ```
  cid:asset_class:locale:mic:symbol
  ```
  Example: `cid:stocks:us:xnys:AAPL`

- **`CanonicalHolding`** — Enriched holding record:
  - `instrument_key` — Canonical identifier
  - `ticker` — Resolved ticker symbol
  - `quantity` — Share count
  - `asset_class` — Asset type (stocks, crypto, etc.)
  - `locale` — Market locale (us, gb, etc.)
  - `mic` — Market Identifier Code (exchange)
  - `name` — Full instrument name
  - `currency` — Trading currency
  - `confidence` — Resolution confidence score (0.0–1.0)

### Market Models (`models/market.py`)
State objects for market comparison features:

- **`ReferenceTickerMetrics`** — Benchmark ticker metrics (returns, Sharpe, volatility)
- **`StockMarketComparison`** — Per-stock comparison vs. benchmarks
- **`PortfolioMarketMetrics`** — Portfolio-level aggregated metrics
- **`MarketContext`** — State container for market comparison pipeline

## Feature Areas

### Wavelet Analysis
Multi-timescale signal decomposition for trend detection:
- MODWT (Maximal Overlap Discrete Wavelet Transform) with Symlet-4 filter
- Configurable decomposition levels (1–8)
- Trend extraction via wavelet coefficient reconstruction
- Visualization overlays on candlestick charts

See: `docs/research/research-wavelet-analysis.md`

### Cone of Influence (COI)
Wavelet boundary effect handling:
- Progressive distortion computation for edge effects
- Filter-weighted COI calculation
- Visualization of confidence regions in wavelet plots

See: `docs/research/cone-of-influence-*.md`

### Boundary Stabilization
Price extension for trend filter edge stabilization:
- Linear and Gaussian Process forecasting strategies
- Noise injection for stochastic extensions
- Continuity adjustment for seamless extension start
- Integration with wavelet analysis pipeline

See: `docs/design/feature-design-boundary-stabilization.md`

### Article Text Extraction
HTML-to-text extraction for news articles:
- Local LLM extraction via Ollama (ReaderLM-v2)
- Batch processing across portfolio tickers
- Experimental feature (disabled by default)

See: `docs/design/feature-design-article-text-extraction.md`

### News Integration
Stock news fetching and summarization:
- Per-ticker news from Polygon.io
- Article HTML caching
- 7-day news + technical reports

See: `docs/design/feature-design-stock-news.md`

## Logging and Error Handling

### Logging Strategy
- Default level: `INFO` with plain text format
- JSON format available for structured log aggregation
- Library noise suppression: LangGraph/LangChain logs hidden by default
- Enable `AGENT_PROGRESS=1` to show detailed execution traces
- Sensitive data (API keys) never logged

### Error Handling Principles
- Fail fast with clear error messages
- Configuration errors detected at startup
- File I/O errors include file paths and context
- LLM validation errors include retry count and schema details
- Network errors include endpoint and timeout information
- All exceptions inherit from custom base classes in `errors.py` for type-safe handling

## Extensibility Guide

### Adding a New Data Provider
1. Create client in `services/` (e.g., `alpha_vantage_client.py`)
2. Implement standard interface: `fetch_ticker_info(symbol: str) -> TickerInfo`
3. Update `SymbolResolver` in `tools/symbol_resolver.py` to use new provider
4. Add configuration settings to `config.py`
5. Update tests with mocked provider responses

### Adding a New Agent
1. Create agent function in `agents/` following the pattern:
   ```python
   def my_agent(state: dict) -> dict:
       # Process state and return updated state
       return {"my_field": result}
   ```
2. Update state schema in `graph.py` with new state keys
3. Add agent to graph topology using `.add_node()` and `.add_edge()`
4. Write unit tests with minimal state fixtures

### Adding a New Analysis Type
1. Create module in `stocks/` (e.g., `momentum.py`)
2. Implement computation function with clear inputs/outputs
3. Add to stock analysis graph in `graphs/stocks.py`
4. Update file-based database schema in `docs/design/stock-analysis-plan.md`
5. Add integration tests with sample OHLC data

### Customizing LLM Prompts
- Parser prompts: `agents/parser.py` — Update `PARSER_SYSTEM_PROMPT` constant
- Analyst prompts: `agents/analyst.py` — Modify prompt templates
- Add version tracking to metadata when changing schemas

## Repository Structure

```
PortfolioAdvisor/
├── src/portfolio_advisor/       # Core application
│   ├── agents/                  # LangGraph agent nodes
│   │   ├── analyst.py           # Portfolio report generation
│   │   ├── basket_narrative.py  # Basket analysis reports
│   │   ├── ingestion.py         # File discovery and text extraction
│   │   ├── market_comparison.py # Market benchmark comparisons
│   │   ├── news_summary.py      # News aggregation and summarization
│   │   ├── parser.py            # LLM-powered holdings extraction
│   │   ├── planner.py           # Document analysis and strategy
│   │   ├── resolver.py          # Symbol resolution orchestration
│   │   └── stock_report_collator.py  # 7-day report collation
│   ├── graphs/                  # LangGraph pipeline definitions
│   │   ├── baskets.py           # Basket analysis workflow
│   │   └── stocks.py            # Stock data collection workflow
│   ├── models/                  # Pydantic data models
│   │   ├── canonical.py         # Post-resolution holdings
│   │   ├── market.py            # Market comparison state objects
│   │   └── parsed.py            # Pre-resolution holdings
│   ├── portfolio/               # Portfolio state management
│   │   └── persistence.py       # Portfolio persistence and history
│   ├── services/                # External API clients
│   │   ├── ollama_service.py    # Local LLM service for text extraction
│   │   └── polygon_client.py    # Polygon.io REST API wrapper
│   ├── stocks/                  # Stock analysis modules
│   │   ├── analysis.py          # Returns, volatility, SMAs
│   │   ├── article_extraction.py # HTML-to-text extraction
│   │   ├── coi_distortion.py    # Cone of influence calculations
│   │   ├── coi_distortion_advanced.py  # Advanced COI methods
│   │   ├── db.py                # File-based stock database & paths
│   │   ├── news.py              # News fetching and caching
│   │   ├── plotting.py          # Chart generation
│   │   └── wavelet.py           # Wavelet decomposition
│   ├── tools/                   # Reusable utilities
│   │   └── symbol_resolver.py   # Ticker resolution logic
│   ├── trend/                   # Trend analysis modules
│   │   └── boundary.py          # Boundary stabilization
│   ├── utils/                   # Helper functions
│   │   ├── fs.py                # Filesystem utilities
│   │   └── slug.py              # Path-safe name generation
│   ├── analyze.py               # Analysis entrypoint
│   ├── cli.py                   # Command-line interface
│   ├── config.py                # Settings and environment handling
│   ├── errors.py                # Custom exception classes
│   ├── graph.py                 # Main portfolio analysis graph
│   ├── io_utils.py              # I/O utilities
│   ├── llm.py                   # LLM client factory
│   └── logging_config.py        # Logging configuration
├── tests/                       # Comprehensive test suite
│   ├── test_*_agent.py          # Agent unit tests
│   ├── test_*_graph.py          # Graph integration tests
│   └── test_*_integration.py    # End-to-end tests
├── docs/                        # Technical documentation
│   ├── Architecture.md          # This file
│   ├── design/                  # Feature design documents
│   │   ├── stock-analysis-plan.md
│   │   └── feature-design-*.md
│   ├── implementation/          # Implementation notes
│   │   ├── IMPLEMENTATION_STATUS.md
│   │   └── *-implementation.md
│   ├── research/                # Research and analysis notes
│   │   ├── research-wavelet-analysis.md
│   │   └── cone-of-influence-*.md
│   └── thirdparty/              # External API documentation
│       └── polygon-io-api-guide.md
├── scripts/                     # Development automation
│   ├── bootstrap                # Environment setup
│   ├── format                   # Code formatting (Black)
│   ├── lint                     # Linting (Ruff)
│   └── test                     # Test runner with coverage
├── input/                       # Sample portfolio files
├── output/                      # Generated analysis outputs
│   ├── portfolio/               # Portfolio state persistence
│   ├── baskets/                 # Basket analysis reports
│   └── stocks/                  # Stock database and charts
└── cache/                       # LLM response cache
```

## Related Documentation

- **README.md** — Quickstart, CLI usage, and configuration reference
- **docs/design/** — Feature specifications and design documents
- **docs/implementation/** — Implementation notes and status tracking
- **docs/research/** — Technical research on wavelet analysis and COI
